---
title: "Homework 3"
author: "Name Rong Li, id:U73933267"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load("bayesplot","knitr","arm","ggplot2","rstanarm")
```


## Disclaimer

A few things to keep in mind :
1) Use set.seed() to make sure that the document produces the same random simulation as when you ran the code.
2) Use refresh=0 for any stan_glm() or stan-based model. lm() or non-stan models don't need this!
3) You can type outside of the r chunks and make new r chunks where it's convenient. Make sure it's clear which questions you're answering.
4) Even if you're not too confident, please try giving an answer to the text responses!
5) Please don't print data in the document unless the question asks. It's good for you to do it to look at the data, but not as good for someone trying to read the document later on.
6) Check your document before submitting! Please put your name where "name" is by the author!
  
```{r}
library(truncnorm)
library(rstanarm)
```
  
## 4.1 Comparison of proportions  
A randomized experiment is performed within a survey. 1000  people are contacted. Half the people contacted are promised a $5 incentive to participate, and  half are not promised an incentive. The result is a 50% response rate among the treated group and 40% response rate among the control group. Give an estimate and standard error of the  average treatment effect.  
  
```{r}
estimate <- 0.5-0.4 
se <-sqrt(0.5*(1-0.5)/500 + 0.4*(1-0.4)/500)
data.frame(Estimate = estimate, Standard_error = se)
```
  
## 4.2 Choosing sample size
You are designing a survey to estimate the gender gap: the difference in  support for a candidate among men and women. Assuming the respondents are a simple random  sample of the voting population, how many people do you need to poll so that the standard error  is less than 5 percentage points?  
  
$\sqrt {\hat p (1-\hat p)/N} = \sqrt {0.5 (1-0.5)/N} < 0.05$  
$N > 100$  
I need at least 100 people to poll.  
  
## 4.4 Designing an experiment
You want to gather data to determine which of two students is a better basketball shooter. You plan to have each student take N shots and then compare their shooting percentages. Roughly how large does N have to be for you to have a good chance of  distinguishing a 30% shooter from a 40% shooter?  
  
$se_1^2=0.3(1-0.3)/N=0.21/N$  
$se_2^2=0.4(1-0.4)/N=0.24/N$  
standard error of the different$=\sqrt {se_1^2 + se_2^2}=\sqrt {0.21/N + 0.24/N} = \sqrt {0.45/N} < 0.05$  
$N>180$  
For me, the N have to be at least 180.  

## 4.6 Hypothesis testing
The following are the proportions of girl births in Vienna for each month in  Girl births 1908 and 1909 (out of an average of 3900 births per month):

```{r}
birthdata <- c(.4777,.4875,.4859,.4754,.4874,.4864,.4813,.4787,.4895,.4797,.4876,.4859,
               .4857,.4907,.5010,.4903,.4860,.4911,.4871,.4725,.4822,.4870,.4823,.4973)
```

The data are in the folder Girls. These proportions were used by von Mises (1957) to support  a claim that that the sex ratios were less variable than would be expected under the binomial  distribution. We think von Mises was mistaken in that he did not account for the possibility that  this discrepancy could arise just by chance.  

### (a) Compute the standard deviation of these proportions and compare to the standard deviation  that would be expected if the sexes of babies were independently decided with a constant  probability over the 24-month period.  

```{r}
sigma_0 <- sqrt(3900*0.5*0.5/3900^2)
data.frame(Sd = sd(birthdata), Expected_sd = sigma_0)
```

### (b) The observed standard deviation of the 24 proportions will not be identical to its theoretical  expectation. In this case, is this difference small enough to be explained by random variation?  Under the randomness model, the actual variance should have a distribution with expected  value equal to the theoretical variance, and proportional to a chi-square random variable with 23  degrees of freedom; see page 53.    
Hypothesis:  
$H_0:\sigma^2 = \sigma_0^2   ,H_1:\sigma^2 \neq \sigma_0^2$  
Test statistic $X^2=\cfrac {(n-1)S^2}{\sigma_0^2} \sim X_{n-1}^2,n=24$  
On the level of 0.05($\alpha = 0.05$), $P(X_{n-1}^2(1-\alpha /2)<\cfrac {(n-1)S^2}{\sigma_0^2}<X_{n-1}^2(\alpha /2))=1-\alpha$  
```{r}
test_stat <- 23*sd(birthdata)^2/(3900*0.5*0.5/3900^2)
data.frame(Test_statistic=test_stat,interval_bottom = qchisq(0.05/2, 23), interval_top = qchisq(1-0.05/2, 23))
```
So I accept the hypothesis$H_0$ when $\alpha=0.05$. This difference is small enough to be explained by random variable.  
  
## 5.5 Distribution of averages and differences
The heights of men in the United States are approximately  normally distributed with mean 69.1 inches and standard deviation 2.9 inches. The heights of  women are approximately normally distributed with mean 63.7 inches and standard deviation  2.7 inches. Let x be the average height of 100 randomly sampled men, and y be the average  height of 100 randomly sampled women. In R, create 1000 simulations of x - y and plot their  histogram. Using the simulations, compute the mean and standard deviation of the distribution  of x - y and compare to their exact values. 

```{r}
z <- array()
#create 1000 simulations of x-y
set.seed(1)
for (i in 1:1000){
  a <- rnorm(100, 69.1, 2.9)
  b <- rnorm(100, 63.7, 2.7)
  x <- mean(a)
  y <- mean(b)
  z[i] <- x-y
}

#plot x-y histgram
hist(z, main = "Histogram of x-y", xlab = "x-y")

#Compute the mean and standard deviation of x-y and campare to their exact values
true_mean <- 69.1-63.7
true_sd <- sqrt((2.9^2 + 2.7^2)/100)
means <- c(true_mean, mean(z))
sds <- c(true_sd, sd(z))
df <- data.frame(means, sds)
rownames(df) <- c("exact values", "simulation values")
df
```

## 5.6 Propagation of uncertainty: 
We use a highly idealized setting to illustrate the use of simulations  in combining uncertainties. Suppose a company changes its technology for widget production,  and a study estimates the cost savings at 5 dollars per unit, but with a standard error of 4 dollars. Furthermore,  a forecast estimates the size of the market (that is, the number of widgets that will be sold)  at 40 000, with a standard error of 10000. Assuming these two sources of uncertainty are  independent, use simulation to estimate the total amount of money saved by the new product  (that is, savings per unit, multiplied by size of the market). 

```{r}
total <- array()
set.seed(1)
for (i in 1:1000){
  savings <- rnorm(1, 5, 4)
  market <- rnorm(1, 40000, 10000)
  total[i] <- savings * market
}

mean(total)
```
The estimate of total amount of money saved by the new product is 193506.7.  
  
## 5.8 Coverage of confidence intervals: 
On page 15 there is a discussion of an experimental study of  an education-related intervention in Jamaica, in which the point estimate of the treatment effect,  on the log scale, was 0.35 with a standard error of 0.17. Suppose the true effect is 0.10—this  seems more realistic than the point estimate of 0.35—so that the treatment on average would  increase earnings by 0.10 on the log scale. Use simulation to study the statistical properties of  this experiment, assuming the standard error is 0.17.  

### (a) Simulate 1000 independent replications of the experiment assuming that the point estimate is  normally distributed with mean 0.10 and standard deviation 0.17.  

```{r}
set.seed(10)
est <- rnorm(1000, 0.1, 0.17)
for(i in 1:1000){
  if(i == 1) effects=rnorm(127, est[i], 0.17)
  else effects=cbind(effects, rnorm(127, effects[i], 0.17))
}
```

### (b) For each replication, compute the 95% confidence interval. Check how many of these intervals  include the true parameter value.  

```{r}
bottom <- array()
top <- array()
for (i in 1:1000){
  bottom[i] <- qnorm(0.025, mean(effects[,i]), sd(effects[,i]))
  top[i] <- qnorm(1-0.025, mean(effects[,i]), sd(effects[,i]))
}
df <- data.frame(interval_bottom = bottom, interval_top = top)
sum(df$interval_bottom<=0.1 & df$interval_top>=0.1)
```

### (c) Compute the average and standard deviation of the 1000 point estimates; these represent the  mean and standard deviation of the sampling distribution of the estimated treatment effect. 

```{r}
data.frame(mean=mean(est), sd=sd(est))
```

## 5.9 Coverage of confidence intervals after selection on statistical significance: 
Take your 1000  simulations from Exercise 5.8, and select just the ones where the estimate is statistically  significantly different from zero. Compute the average and standard deviation of the selected  point estimates. Compare these to the result from Exercise 5.8. 

```{r}

```

## 9.8 Simulation for decision analysis: 
An experiment is performed to measure the efficacy of a  television advertising program. The result is an estimate that each minute spent on a national  advertising program will increase sales by 500,000 dollars, and this estimate has a standard error of  200000 dollars. Assume the uncertainty in the treatment effect can be approximated by a normal  distribution. Suppose ads cost 300000 dollars per minute. What is the expected net gain for purchasing 20 minutes of ads? What is the probability that the net gain is negative?   
  
```{r}
set.seed(1)
earnings <- replicate(100000, sum(rnorm(20, 500000, 200000))-20*300000)
data.frame(Expected_net_gain = mean(earnings), The_probability = sum(earnings<0)/length(earnings))
```
  
## 10.3 Checking statistical significance: 
In this exercise and the next, you will simulate two variables  that are statistically independent of each other to see what happens when we run a regression to  predict one from the other. Generate 1000 data points from a normal distribution with mean 0  and standard deviation 1 by typing var1 <- rnorm(1000,0,1) in R. Generate another variable  in the same way (call it var2). Run a regression of one variable on the other. Is the slope  coefficient “statistically significant”? We do not recommend summarizing regressions in this way, but it can be useful to understand how this works, given that others will do so. 
  
```{r}
library(rstanarm)
set.seed(1)
var1 <- rnorm(1000, 0, 1)
var2 <- rnorm(1000, 0, 1)
#run a regression 
fit <- stan_glm(var2~var1, refresh = 0)
coef(fit)[2]
```
Slope coefficient = 0.0055  
No, the slope coefficient is not "statistically significant".  
  
## 10.4 Simulation study of statistical significance: 
Continuing the previous exercise, run a simulation  repeating this process 100 times. This can be done using a loop. From each simulation, save the  z-score (the estimated coefficient of var1 divided by its standard error). If the absolute value of  the z-score exceeds 2, the estimate is “statistically significant.”  To perform this computation, we start by creating an empty vector of z-scores filled with missing values (NAs). Another approach is to start with z_scores <- numeric(length=100), which  would set up a vector of zeroes. In general, however, we prefer to initialize with NAs, because  then when there is a bug in the code, it sometimes shows up as NAs in the final results, alerting  us to the problem. 

How many of these 100 z-scores exceed 2 in absolute value, thus achieving the conventional  level of statistical significance?   

```{r}
set.seed(1)
z_scores <- rep(NA, 100)
for (k in 1:100){
  var1 <- rnorm(1000, 0, 1)
  var2 <- rnorm(1000, 0, 1)
  fake <- data.frame(var1, var2)
  fit <- stan_glm(var2~var1, data = fake, refresh = 0)
  z_scores[k] <- coef(fit)[2]/se(fit)[2]
}

df <- data.frame(z_scores)
df1 <- subset(df, z_scores > 2 & z_scores < -2)
length(df1)
```

## 11.3 Coverage of confidence intervals: 
Consider the following procedure:  

- Set n = 100 and draw n continuous values xi uniformly distributed between 0 and 10. Then  simulate data from the model yi = a + bxi + errori, for i = 1,..., n, with a = 2, b = 3, and  independent errors from a normal distribution.  

- Regress y on x. Look at the median and mad sd of b. Check to see if the interval formed by  the median ± 2 mad sd includes the true value, b = 3.  

- Repeat the above two steps 1000 times.  


### (a) True or false: the interval should contain the true value approximately 950 times. Explain  your answer.  

```{r}
n <- 100
a <- 2
b <- 3
count <- 0
set.seed(3)
for(i in 1:1000){
  x <- runif(n, 0, 10)
  error <- rnorm(n, 0, 1)
  y <- a + b*x + error
  fit <- lm(y~x)
  interval <- c(coef(fit)[2] - 2*summary(fit)$cov.unscaled[4],
                coef(fit)[2] + 2*summary(fit)$cov.unscaled[4])
  if(interval[1]<3 && interval[2]>3){
    count <- count+1
  }
}
data.frame(Numbers_of_contain = 1000-count, Probability = (1000-count)/1000)
```
True. It means there is a probability of 94.4% that the interval(median-2mad_sd, median+2mad_sd) contains b=3.  
  
### (b) Same as above, except the error distribution is bimodal, not normal. True or false: the  interval should contain the true value approximately 950 times. Explain your answer.   
  
```{r}
set.seed(3)
count <- 0
for(i in 1:1000){
  x <- runif(n, 0, 10)
  error <- c(rtruncnorm(n/2, a=1, b=5, mean=0, sd=1),
             rtruncnorm(n/2, a=1, b=5, mean=4, sd=1))
  y <- a + b*x + error
  fit <- lm(y~x)
  interval <- c(coef(fit)[2] - 2*summary(fit)$cov.unscaled[4],
                coef(fit)[2] + 2*summary(fit)$cov.unscaled[4])
  if(interval[1]<3 && interval[2]>3){
    count <- count+1
  }
}
data.frame(Numbers_of_contain = 1000-count, Probability = (1000-count)/1000)
```
True. It means there is a probability of 95.6% that the interval(median-2mad_sd, median+2mad_sd) contains b=3.  
  